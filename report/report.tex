\documentclass{article}
\usepackage[margin=3cm]{geometry} % TODO: adjust margin
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{url} %, csquotes}
\usepackage[bookmarks]{hyperref}
\usepackage{enumitem}
%\usepackage{breqn}
\newcommand{\code}[1]{\texttt{#1}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\eps}{\varepsilon}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\relu}{\text{ReLU}}

% \theoremstyle{definition}
% \newtheorem{definition}{Definition}
% \newtheorem{notation}{Notation}
% \newtheorem{theorem}{Theorem}
% \newtheorem{proposition}{Proposition}
% \theoremstyle{remark}
% \newtheorem{remark}{Remark}
% \usepackage{graphicx}
% \usepackage{caption}
% \usepackage{subcaption}
% \usepackage{ulem}
% \usepackage[shortlabels]{enumitem}
% \setlist[itemize]{label=\textbullet}

\title{Reliable and Interpretable Artificial Intelligence \\ project report}
\author{Simone \textsc{Barbaro}, Guillaume \textsc{Wang}}
\date{\small{ December 2019 (HS2019)}}

\begin{document}
\maketitle

\section{Zonotope representation and transformation}

We represent a zonotope $Z$ by its center $a_0 \in \RR^d$ and a tensor $A \in \RR^{k \times d}$ representing the coefficient of the $k$ error terms.

Zonotope propagation through the neural network is straightforward using the transformations presented during the course.
For convolutional layers, it suffices to apply the convolution to $A$ itself (excluding bias).
The proof is not reproduced here due to space restrictions.

\section{Loss function and learning \texorpdfstring{$\lambda$'s}{lambdas}}

Let $[o_0, o_2, ... o_9]$ be the output layer of the neural network (the logits for the MNIST digit classification). 
Let $Z_{out} =: Z$ be the zonotope region at the output layer, for a given input region $Z_{in}$, and for given ReLU-transformation parameters $\lambda$.

Then the network is verifiably robust on the input region if:
\begin{align}
    &\forall (o_0, ..., o_9) \in Z, \forall i \in \{0, ..., 9\}, o_i \leq o_t \nonumber \\
    \iff & \forall (x_0, ..., x_9) \in Z', \forall i \in \{0, ..., 9\}, x_i \leq 0 \nonumber \quad
    \iff Z' \subset \RR_{-}^{10} \label{eq:verified_iff} \tag{*}
\end{align}
where $Z'$ is the zonotope of the "violations" $[x_0, ..., x_9] := [o_0 - o_t, ..., o_9 - o_t]$.
There are multiple ways of translating this property into a loss function.

\paragraph{Maximum violation (\texttt{zMaxViolation})}
\begin{align*}
    ( \ref{eq:verified_iff} )
    \iff & \forall x \in Z', \forall i, x_i \leq 0 \\
    \iff & \forall i, \forall x \in Z'_i, x_i \leq 0 \\
    \iff & \max_i \max_{x \in Z'_i} x_i \leq 0
\end{align*}
where $Z'_i$ is the zonotope of $x_i$ ($Z'_i = \{ x_i; \exists y \in Z', y_i = x_i \}$).
Since $Z'_i$ are one-dimensional zonotopes, the innermost max can be computed in $O(1)$ by assigning all the error terms to the sign of the corresponding coefficients.

\paragraph{Sum of maximum individual violations (\texttt{zSumOfMaxIndividualViolations})}
\begin{align*}
    ( \ref{eq:verified_iff} )
    \iff & \forall i, \max_{x \in Z'_i} x_i \leq 0 \\
    \iff & \sum_i \left( \max_{x \in Z'_i} x_i \right)^+ \leq 0 \\
\end{align*}
Note that $\max_{x \in Z'_i} x_i$ is just a scalar, so taking its positive part is easy.

\paragraph{Maximum sum of violations (\texttt{zMaxSumOfViolations})}
\begin{align*}
    ( \ref{eq:verified_iff} )
    \iff & \forall x \in Z', \forall i, x_i \leq 0 \\
    \iff & \forall x \in Z', \sum_i x_i^+ = \sum_i \relu(x_i) \leq 0 \\
    \iff & \max_{x \in Z'} \sum_i \relu(x_i) = \max Z'' \leq 0  
\end{align*}
where $Z''$ is the zonotope of $\sum_i \relu(x_i)$
Note that computing this requires performing an additional ReLU zonotope transformation.

Recall that $Z_{out}$ (and so $Z'_i$ and $Z''$) depends on the ReLU-transformation parameters $\lambda$. Each of the possible loss functions:
\footnote{In practice, all three loss functions seemed to yield similar performances, with "maximum sum of violations" being slightly slower due to the additional ReLU transformation.}
\begin{align}
    L(\lambda) &= \max_i \max_{x_i \in Z'_i} x_i                 \tag{maximum violation} \\
    L(\lambda) &= \sum_i \left( \max_{x \in Z'_i} x_i \right)^+  \tag{sum of maximum individual violations} \\ 
    L(\lambda) &= \max Z''                                       \tag{maximum sum of violations}
\end{align}
can be computed by propagating the input zonotope $Z_{in}$ through the network.
The network is verifiably robust if there exists $\lambda$ such that $L(\lambda) \leq 0$.

Finally, $L(\lambda)$ is differentiable, so we use gradient-based methods to minimize it.

\section{Optimizer selection}

We used the optimizers from \texttt{pytorch.optim} to optimize the loss function $L(\lambda)$. 
To select which method and which hyperparameters (e.g. learning rate) to use, we performed a hyperparameter search using \href{https://github.com/facebook/Ax}{Ax}.
The criterion used was the verifier execution time (capped by a timeout).
We were able to do this by using additional test cases, which we generated ourselves.

\section{Test case generation and self-evaluation}

We generated additional test cases by doing the following:
\begin{itemize}[noitemsep]
    \item Generate random datapoints of MNIST images and epsilons (randomly drawn in $[0.005, 0.2]$).
    \item Use adversarial attacks implemented in the \href{https://github.com/IBM/adversarial-robustness-toolbox/}{ART} library to classify them into "maybe robust" and "not robust".
    \item Make sure our verifier is sound, by running it on the "not robust" datapoints with a long timeout.
    \item Use our own verifier to further refine this classification, by running it on the "maybe robust" datapoints with a long timeout, thus yielding some "verifiable" datapoints.
\end{itemize}

\end{document}
