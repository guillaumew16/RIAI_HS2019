\documentclass{article}
\usepackage[margin=3cm]{geometry} % TODO: adjust margin
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{url} %, csquotes}
\usepackage[bookmarks]{hyperref}
\usepackage{enumitem}
%\usepackage{breqn}
\newcommand{\code}[1]{\texttt{#1}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\eps}{\varepsilon}
\newcommand{\ind}{\mathbbm{1}}

% \theoremstyle{definition}
% \newtheorem{definition}{Definition}
% \newtheorem{notation}{Notation}
% \newtheorem{theorem}{Theorem}
% \newtheorem{proposition}{Proposition}
% \theoremstyle{remark}
% \newtheorem{remark}{Remark}
% \usepackage{graphicx}
% \usepackage{caption}
% \usepackage{subcaption}
% \usepackage{ulem}
% \usepackage[shortlabels]{enumitem}
% \setlist[itemize]{label=\textbullet}

\title{Reliable and Interpretable Artificial Intelligence \\ project report}
\author{Simone \textsc{Barbaro}, Guillaume \textsc{Wang}}
\date{\small{ December 2019 (HS2019)}}

\begin{document}
\maketitle

\section{Zonotope representation and transformation}

We represent a zonotope $Z$ by its center $a_0 \in R^d$ and a non-negative tensor $A \in R^{k \times d}$ representing the coefficient of the $k$ error terms.

Zonotope propagation through the neural network is straightforward using the transformations presented during the course.
For convolutional layers, it suffices to apply the convolution to $A$ itself (excluding bias).
The proof is not reproduced here due to space restrictions.

\section{Loss function and learning lambdas}

Let $[o_0, o_2, ... o_9]$ be the output layer of the neural network (the logits for the MNIST digit classification). 
Let $Z$ be the zonotope region at the output layer, for a given input region, and for given ReLU-transformation parameters $\lambda$.

Then the network is verifiably robust on the input region if:
\begin{align*}
    \forall (o_0, ..., o_9) \in Z, \forall i \in \{0, ..., 9\}, o_i &\leq o_t \\
    \forall (x_0, ..., x_9) \in Z', \forall i \in \{0, ..., 9\}, x_i &\leq 0 \\
    \max_{x \in Z'} \max_i x_i &\leq 0 \\
    \max_i \max_{x \in Z'_i} x_i &\leq 0
\end{align*}
where $Z'$ is the zonotope of the "violations" $[o_0 - o_t, ..., o_0 - o_t]$, and $Z'_i$ is the zonotope of $o_i - o_t$.

Since $Z'_i$ are one-dimensional zonotopes, the innermost max can be computed in $O(1)$ by assigning all the error terms to the sign of the corresponding coefficients.

Recall that $Z'_i$ depends on the ReLU-transformation parameters $\lambda$. The loss function:
\begin{equation*}
    L(\lambda) = \max_i \max_{x_i \in Z'_i} x_i
\end{equation*}
can be computed by propagating the input zonotope through the network.
The network is verifiably robust if there exists $\lambda$ such that $L(\lambda) \leq 0$.

Finally, $L(\lambda)$ is differentiable, so we use gradient-based methods to minimize it.

\section{Optimizer selection}

We used the optimizers from \texttt{pytorch.optim} to optimize the loss function $L(\lambda)$. 
To select which method and which hyperparameters (e.g. learning rate) to use, we performed a grid search using \href{https://github.com/facebook/Ax}{Ax}.
The criterion used was the verifier execution time (capped by a timeout).
We were able to do this by using additional test cases, which we generated ourselves.

\section{Test case generation and self-evaluation}

We generated additional test cases by doing the following:
\begin{itemize}[noitemsep]
    \item Generate random datapoints of MNIST images and epsilons (randomly drawn in $[0.005, 0.2]$).
    \item Use adversarial attacks implemented in the \href{https://github.com/IBM/adversarial-robustness-toolbox/}{ART} library to classify them into "maybe robust" and "not robust".
    \item Make sure our verifier is sound, by running it on the "not robust" datapoints with a long timeout.
    \item Use our own verifier to further refine this classification, by running it on the "maybe robust" datapoints with a long timeout, thus yielding some "verifiable" datapoints.
\end{itemize}

\end{document}
