Long-term:
- Use PGD or an open-source verifier to generate more test cases
- When noticed, mark suspicious lines as TODO or DEBUG with a comment
- Reduce the size of the computation graph of loss and znet
- Write a hyperparameter search in order to test different optimizer and different parameters of these optimizers, doing CV on mnist with random epsilons
- Instead of hyperparameter selection as described above, we could even do ensembling of the best methods found by that process.

Todo before production:
- check for TODOs in the source
- remove or review lines marked with a "DEBUG" comment
- make sure to ignore asserts, i.e run with "-O" flag
- and obviously review the whole thing again
